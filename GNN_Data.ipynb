{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23fb98df-1a61-40d6-baa9-2fe127ce4ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras import layers\n",
    "import spektral\n",
    "import os\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a2f7975-97ab-4ed4-b5cf-f9602b994c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 95\n",
    "bus = 73\n",
    "samples = 20000\n",
    "Bus_data = loadtxt('BusData.dat')\n",
    "Gen_data = loadtxt('GenData.dat')\n",
    "Bra_data = loadtxt('BranchData.dat')\n",
    "\n",
    "PD = loadtxt(('Pd_Profile_%d.csv' %bus), delimiter=',')   #Load Profile\n",
    "PF = loadtxt(('PF_Profile_%d.csv' %bus), delimiter=',')   #Branch Profile\n",
    "Pg = loadtxt(('Pg_Profile_%d.csv' %bus), delimiter=',')   #Generation Profile\n",
    "TC = loadtxt(('TC_Profile_%d.csv' %bus), delimiter=',')   #Total Cost \n",
    "\n",
    "branch = Bra_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2916308e-927a-4e6a-92f1-1f322df96f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize each features to within the range between 0 and 1 (Don't use)\n",
    "def norm(data):\n",
    "    max_val = np.amax(data,1,keepdims=1)\n",
    "    normalize = np.divide(data,max_val)\n",
    "    return normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbed545b-c596-46d3-901f-c193ef1722ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sum up the total amount of generation per bus\n",
    "# Pg_Bus = np.zeros([samples,bus])\n",
    "# for i in range(bus):\n",
    "#     index = np.nonzero(Gen_data[:,2] == Bus_data[i,1])\n",
    "#     Pg_Bus[:,i] = np.squeeze(np.sum(Pg[:,index],axis = 2))\n",
    "\n",
    "\n",
    "# Sum up the total amount of generation capacity and cost per bus\n",
    "Pg_Cap = np.zeros([bus,2])\n",
    "for i in range(bus):\n",
    "    index = np.nonzero(Gen_data[:,2] == Bus_data[i,1])\n",
    "    Pg_Cap[i] = np.sum(np.squeeze(Gen_data[index,3:5]),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "414b6749-0eb7-4948-8a04-eceeb281641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label for graph\n",
    "\n",
    "Label = np.zeros([samples,PF.shape[1]])\n",
    "PF_Percent = PF / Bra_data[:,5]\n",
    "\n",
    "# Label each branch as either 1 or 0 based on flow condition\n",
    "Label = (np.abs(PF_Percent) >= level/100 * 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13fc658d-1bc4-48a4-9d7b-17fb3626b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.all([(np.abs(PF_Percent) <= 0.95),(np.abs(PF_Percent) > 0.75)], axis = 0) * 2 + \\\n",
    "# (np.abs(PF_Percent) > 0.95) * 3\n",
    "# np.all([(np.abs(PF_Percent) <= 0.95),(np.abs(PF_Percent) > 0.85)], axis = 0) * 3 + \\\n",
    "\n",
    "\n",
    "\n",
    "# Label each branch as combination of 0, 0, 0, 0\n",
    "# Label[:,:,0] = (np.abs(PF_Percent) <= 0.75 ) * 1 \n",
    "# Label[:,:,1] = np.all([(np.abs(PF_Percent) <= 0.85),(np.abs(PF_Percent) > 0.75)], axis = 0) * 1 \n",
    "# Label[:,:,2] = np.all([(np.abs(PF_Percent) <= 0.95),(np.abs(PF_Percent) > 0.85)], axis = 0) * 1 \n",
    "# Label[:,:,3] = (np.abs(PF_Percent) > 0.95) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bf90015-d07c-4275-8ebf-f87438e02657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Edge features\n",
    "EF = np.zeros([samples,branch,3])\n",
    "EF[:,:,0] = Bra_data[:,4]        #Reactant\n",
    "EF[:,:,1] = Bra_data[:,5]        #Line Limit\n",
    "EF[:,:,2] = Bra_data[:,6]        #Number of parallel lines\n",
    "EF = EF\n",
    "\n",
    "# Create Node features\n",
    "NF = np.zeros([samples,bus,5])\n",
    "NF[:,:,0]   = PD              #Load Profile\n",
    "NF[:,:,1:3] = Pg_Cap          #Generator Profile\n",
    "node = np.zeros([bus])\n",
    "for i in range(bus):\n",
    "    node[i] = np.sum( Bra_data[:,2]-1 == i) + np.sum( Bra_data[:,3]-1 == i)\n",
    "NF[:,:,3] = node              #Number of branches connect to each node\n",
    "NF[:,:,4] = Bus_data[:,3]     #Bus Type\n",
    "# NF[:,:,1]   = Pg_Bus\n",
    "NF = NF\n",
    "\n",
    "\n",
    "# Create Adjacency matrix\n",
    "# AM = np.zeros([bus,bus])\n",
    "AM = sp.csr_matrix((np.ones(branch), (Bra_data[:,2]-1, Bra_data[:,3]-1)), shape = [bus,bus]).toarray()# + sp.csr_matrix((np.ones(branch), (Bra_data[:,3]-1, Bra_data[:,2]-1)), shape = [bus,bus])sp.csr_matrix((np.ones(branch), (Bra_data[:,2]-1, Bra_data[:,3]-1)), shape = [bus,bus]).toarray()\n",
    "\n",
    "# AM = np.zeros([samples,branch,3])\n",
    "# AM[:,:,0] = Bra_data[:,2]-1        #Branch From\n",
    "# AM[:,:,1] = Bra_data[:,3]-1        #Branch To\n",
    "# AM[:,:,2] = np.ones(branch)      #Weight of each branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1753bd2-e8e2-4148-b54e-27eacefdded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph files and save them into the folder GNN_Graph\n",
    "path = 'GNN_Graph'\n",
    "\n",
    "for i in range(samples):\n",
    "    filename = os.path.join(path,f'GNN_{i}')\n",
    "    np.savez_compressed(filename, x = NF[i,:,:], a = AM, e = EF[i,:,:], y = Label[i,:]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c4ac072-6d3d-49b6-8ed7-108a75c48d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code from down here is for DGL\n",
    "\n",
    "\n",
    "# import dgl\n",
    "# import torch\n",
    "# from dgl.data import DGLDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e0988f-2551-4af6-af82-1410e28d132b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load data in to graph dataset for DGL\n",
    "\n",
    "# class GNNDataset(DGLDataset):\n",
    "#     def __init__(self):\n",
    "#         super().__init__(name='OPF')\n",
    "\n",
    "#     def process(self):\n",
    "#         self.graphs = []\n",
    "\n",
    "#         node_features = torch.Tensor(NF)\n",
    "#         edge_labels   = torch.Tensor(Label)\n",
    "#         edge_features = torch.Tensor(EF)\n",
    "#         edges_src     = torch.from_numpy(np.short(Bra_data[:,2]-1))\n",
    "#         edges_dst     = torch.from_numpy(np.short(Bra_data[:,3]-1))\n",
    "        \n",
    "#         for i in range(node_features.shape[0]):\n",
    "#             g = dgl.graph((edges_src, edges_dst), num_nodes=node_features.shape[1])\n",
    "#             g.ndata['feat']  = node_features[i,:,:]\n",
    "#             g.edata['label'] = edge_labels[i]\n",
    "#             g.edata['feat']  = edge_features[i,:,:]\n",
    "            \n",
    "            \n",
    "#             self.graphs.append(g)\n",
    "            \n",
    "#             # Load and save graph\n",
    "#             # dgl.load_graphs('graph.dgl')\n",
    "#             # dgl.save_graphs('GNN.dgl', g)\n",
    "            \n",
    "\n",
    "#     def __getitem__(self,i):\n",
    "#         return self.graphs[i]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37111b49-ae90-4832-9858-0a5dce21cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = GNNDataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "406c9f28-c2d1-416e-9470-fa091eaa9443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset)\n",
    "# from dgl.dataloading import GraphDataLoader\n",
    "# dataloader = dgl.dataloading.GraphDataLoader(dataset, batch_size=500, shuffle=True, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da6588b0-d288-410d-99bf-cfc4a7b0acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dgl.data import CiteseerGraphDataset \n",
    "\n",
    "# dataset2 = CiteseerGraphDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59a4cb3d-bc56-4361-b0d1-6767bb8198c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dgl.data import SSTDataset\n",
    "# dataset3 = SSTDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b9de7d1-dbe2-4f26-9ae8-9e4fbf85b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2a7cddc-7887-44a7-9898-9c0efba25255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dgl.nn as dglnn\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# class SAGE(nn.Module):\n",
    "#     def __init__(self, in_feats, hid_feats, out_feats):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = dglnn.SAGEConv(\n",
    "#             in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
    "#         self.conv2 = dglnn.SAGEConv(\n",
    "#             in_feats=hid_feats, out_feats=out_feats, aggregator_type='mean')\n",
    "\n",
    "#     def forward(self, graph, inputs):\n",
    "#         # inputs are features of nodes\n",
    "#         h = self.conv1(graph, inputs)\n",
    "#         h = F.relu(h)\n",
    "#         h = self.conv2(graph, h)\n",
    "#         return h\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "        \n",
    "# class MLPPredictor(nn.Module):\n",
    "#     def __init__(self, in_features, out_classes):\n",
    "#         super().__init__()\n",
    "#         self.W = nn.Linear(in_features * 2, out_classes)\n",
    "\n",
    "#     def apply_edges(self, edges):\n",
    "#         h_u = edges.src['h']\n",
    "#         h_v = edges.dst['h']\n",
    "#         score = self.W(torch.cat([h_u, h_v], 1))\n",
    "#         return {'score': score}\n",
    "\n",
    "#     def forward(self, graph, h):\n",
    "#         # h contains the node representations computed from the GNN defined\n",
    "#         # in the node classification section (Section 5.1).\n",
    "#         with graph.local_scope():\n",
    "#             graph.ndata['h'] = h\n",
    "#             graph.apply_edges(self.apply_edges)\n",
    "#             return graph.edata['score']        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self, in_features, hidden_features, out_features):\n",
    "#         super().__init__()\n",
    "#         self.sage = SAGE(in_features, hidden_features, out_features)\n",
    "#         self.pred = MLPPredictor()\n",
    "#     def forward(self, g, x):\n",
    "#         h = self.sage(g, x)\n",
    "#         return self.pred(g, h)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db54c29c-6f93-45ce-95f2-a3c2a2846f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, graph, features, labels, mask):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         logits = model(graph, features)\n",
    "#         logits = logits[mask]\n",
    "#         labels = labels[mask]\n",
    "#         _, indices = torch.max(logits, dim=1)\n",
    "#         correct = torch.sum(indices == labels)\n",
    "#         return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0537c66e-2739-48ad-b9b3-2c43898b0e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SAGE(in_feats=n_features, hid_feats=100, out_feats=n_labels)\n",
    "# opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# for epoch in range(10):\n",
    "#     model.train()\n",
    "#     # forward propagation by using all nodes\n",
    "#     logits = model(graph, node_features)\n",
    "#     # compute loss\n",
    "#     loss = F.cross_entropy(logits[train_mask], node_labels[train_mask])\n",
    "#     # compute validation accuracy\n",
    "#     acc = evaluate(model, graph, node_features, node_labels, valid_mask)\n",
    "#     # backward propagation\n",
    "#     opt.zero_grad()\n",
    "#     loss.backward()\n",
    "#     opt.step()\n",
    "#     print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "253b7476-8021-467c-b1f9-c0c453898159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.layers import Dropout, Input\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# from spektral.data.loaders import SingleLoader\n",
    "# from spektral.datasets.citation import Citation\n",
    "# from spektral.layers import ARMAConv\n",
    "# from spektral.transforms import LayerPreprocess\n",
    "\n",
    "# dataset = Citation(\"cora\", transforms=[LayerPreprocess(ARMAConv)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
